######### Detecting if the colnames are the correct ones ############
if (!("daf" %in% colnames(x) & "pS" %in% colnames(x) & "pN" %in% colnames(x)))
stop("required header doesn't have the correct names: daf, pN, pS")
#error handling: check data formatting
if (NCOL(x) != 3)
stop("argument x does not contain exactly three tab-separated columns")
if (NROW(x) <= 0)
stop("argument x contains no data rows")
if (NCOL(y) != 6)
stop("argument y does not contain exactly six tab-separated columns")
if (NROW(y) <= 0)
stop("argument y contains no data rows")
##assign proper names to the columns of x and y. MUST CHECK THAT!
####Not defined######
#names(x) <- c("daf", "pN", "pS")
#names(y) <- c("Chr",  "Pop",	"m0f",	"D0f",	"m4f",	"D4f")
#error handling: input colnames
#for arg x
x.cols <- names(x)
suppressWarnings(#the goal is to generate NAs here, so we dont need no warnings
if (!is.na(as.numeric(x.cols[1])) ||
!is.na(as.numeric(x.cols[2])) ||
!is.na(as.numeric(x.cols[3])))
stop("argument x has a numeric column name;
probably the required header row is missing"))
#for arg y
y.cols <- names(y)
suppressWarnings(
if (!is.na(as.numeric(y.cols[1])) ||
!is.na(as.numeric(y.cols[2])) ||
!is.na(as.numeric(y.cols[3])) ||
!is.na(as.numeric(y.cols[4])) ||
!is.na(as.numeric(y.cols[5])) ||
!is.na(as.numeric(y.cols[6])))
stop("argument y has a numeric column name;
probably the required header row is missing")
)
##parse the data from argument x
####### dependent on the column name
f <- x$daf #derived alelle frequencies
p <- x$pN #non-synonymous polymorphism
p0 <- x$pS #synonymous polymorphism
#error handling: check if variables are good
if (any(is.na(f)))
stop("f contains NA values (not allowed)")
if (any(is.na(p)))
stop("p contains NA values (not allowed)")
if (any(is.na(p0)))
stop("p0 contains NA values (not allowed)")
if (is.null(f))
stop("f malformed (must be numeric)")
if (is.null(p))
stop("p malformed (must be numeric)")
if (is.null(p0))
stop("p0 malformed (must be numeric)")
#error handling: check if variables are numeric
if (!is.numeric(f))
stop("f is not numeric")
if (!is.numeric(p))
stop("p is not numeric")
if (!is.numeric(p0))
stop("p0 is not numeric")
#error handling: check if variables are not out of bounds
if (any(f < 0.0) || any(f > 1.0))
stop("f contains values out of the required range [0,1]")
if (all(f == 0))
stop("f contains all values == 0 (not allowed)")
if (any(p < 0))   # note that zero is allowed, although not recommended
stop("p contains values < 0 (not allowed)")
if (all(p == 0))    # not all can be zero, however
stop("p contains all values == 0 (not allowed)")
if (any(p0 <= 0))
stop("p0 contains values <= 0 (not allowed)")
if (all(p0 == 0))
stop("p0 contains all values == 0 (not allowed)")
#error handling: check if argument x has enough data points
if (NROW(x) < 3)
stop("argument x: at least three data rows are required to constrain the fit")
##parse the data from argument y and force it to be numeric...
m <- as.numeric(y$m0f) #number of non-synonymous sites
m0 <- as.numeric(y$m4f) ##number of synonymous sites
d <- as.numeric(y$D0f) #non-synonymous divergence
d0 <- as.numeric(y$D4f) #synonymous divergence
#error handling: check if variables are good
if (is.na(m) || is.null(m))
stop("malformed m (must be numeric)")
if (is.na(m0) || is.null(m0))
stop("malformed m0 (must be numeric)")
if (is.na(d0) || is.null(d0))
stop("malformed d0 (must be numeric)")
if (is.na(d) || is.null(d))
stop("malformed d (must be numeric)")
if (is.na(xlow) || is.null(xlow))
stop("malformed xlow (must be numeric)")
if (is.na(xhigh) || is.null(xhigh))
stop("malformed xhigh (must be numeric)")
# Checks if number of sites (m, m0) is not higher than divergenge (d, d0), the sum of the polimorphisms (p|p0) or the divergenge + the sum of the polimorphsms
if (d>m || sum(p)>m || sum(p)+d>m)
stop("m must be higher than p, d and p+d")
if (d0>m0 || sum(p0)>m0 || sum(p)+d0>m0)
stop("m0 must be higher than p0, d0 and p0+d0")
#error handling: check if variables are numeric
#it makes no sence as we forced them to be numeric... should check that!
if (!is.numeric(m))
stop("m is not numeric")
if (!is.numeric(m0))
stop("m0 is not numeric")
if (!is.numeric(d))
stop("d is not numeric")
if (!is.numeric(d0))
stop("d0 is not numeric")
#error handling: check if variables are not out of bounds
if (m <= 0)
stop("m must be greater than zero")
if (m0 <= 0)
stop("m0 must be greater than zero")
if (d0 <= 0)
stop("d0 must be greater than zero")
if (d <= 0)
stop("d must be greater than zero")
#error handling: check if cutoff values not null
if (is.na(xlow) || is.null(xlow))
stop("malformed xlow (must be numeric)")
if (is.na(xhigh) || is.null(xhigh))
stop("malformed xhigh (must be numeric)")
#error handling: check if cutoff values are numeric
if (!is.numeric(xlow))
stop("xlow is not numeric")
if (!is.numeric(xhigh))
stop("xhigh is not numeric")
#error handling: check if cutoff values are not out of bounds
if ((xlow < 0.0) || (xlow > 1.0))
stop("xlow must be in the interval [0,1]")
if ((xhigh < 0.0) || (xhigh > 1.0))
stop("xhigh must be in the interval [0,1]")
if (xhigh <= xlow)
stop("xhigh must be greater than xlow")
cutoff_f1 <- xlow
cutoff_f2 <- xhigh
trim <- ((f >= cutoff_f1) & (f <= cutoff_f2))
#error handling: check if trimmed f has enough data points
if (sum(trim) < 3)
stop("Argument x: at least 3 data rows are required to constrain the fit;
after trimming the frequency range there are less than 3.
Consider changing cutoff values or not trimming your data.")
data_is_good <- TRUE
#writeLines("data is good: TRUE\n")
return(data_is_good)
}
## 3rd. perform analysis ##
w <- iMK(x, y, 0, 1)
## 3rd. perform analysis ##
w <- iMK(x, y, 0, 1)
## 3rd. perform analysis ##
w <- iMK(x, y, 0, 1)
x
## 2nd. read data ##
#setwd("...")
x <- read.table("RAL_Chr2L.txt", header=T) #polymorphism file (DAF)
y <- read.table("RAL_Chr2L_div.txt", header=T) #divergence and m file
## 3rd. perform analysis ##
w <- iMK(x, y, 0, 1)
# core code for two-step nls2() model fit at a given level of precision (res, usually set at 10)
# alpha_trimmed and f_trimmed correspond to the vectors with alpha and frequency (DAF) values
fitMKmodel <- function(alpha_trimmed, f_trimmed, res) {
## load nls2 package
require(nls2, quietly=T)
## first fitting using starting values (st)
mod <- tryCatch({
## starting values to fit the model
st <- expand.grid(const_a=seq(-1,1,length.out=res + 1), const_b=seq(-1,1,length.out=res), const_c=seq(1,10,length.out=res + 1))
## fitting
nls2(alpha_trimmed ~ const_a + const_b * exp(-const_c* f_trimmed), start=st, algorithm="brute-force", control=nls.control(maxiter=NROW(st)))
}, error=function(cond) {}) ## return condition of error when unable to fit
## if mod fails...
if (length(mod) == 0) { return(NULL) }
## second fitting, starting from previous fit (mod)
mod2 <- tryCatch({
nls2(alpha_trimmed ~ const_a + const_b * exp(-const_c* f_trimmed), start = mod, control=nls.control(maxiter=200))
}, error=function(cond) {}) ## same error handling than the previous step
## if mod2 fails...
if (length(mod2) == 0) { return(NULL) }
## return mod2 if fitted
return(mod2)
}
## 3rd. perform analysis ##
w <- iMK(x, y, 0, 1)
# Get a CI using Monte Carlo simulation based upon a fitted model.  This is necessary because
# getting confidence intervals for non-linear models is a complicated business, apparently.
# Thanks to Andrej-Nikolai Spiess (http://www.dr-spiess.de) for this code.
# See: https://www.r-bloggers.com/predictnls-part-1-monte-carlo-simulation-confidence-intervals-for-nls-models/
# Or, if that link goes stale: http://stats.stackexchange.com/a/251501/141766
# directly retrieved from: https://github.com/MesserLab/asymptoticMK
predictNLS <- function(object, newdata, level = 0.95, nsim = 10000) {
## define required packages
require(MASS, quietly = TRUE)
## get right-hand side of formula
RHS <- as.list(object$call$formula)[[3]]
EXPR <- as.expression(RHS)
## all variables in model
VARS <- all.vars(EXPR)
## coefficients
COEF <- coef(object)
## extract predictor variable
predNAME <- setdiff(VARS, names(COEF))
## take fitted values, if 'newdata' is missing
if (missing(newdata)) {
newdata <- eval(object$data)[predNAME]
colnames(newdata) <- predNAME
}
## check that 'newdata' has same name as predVAR
if (names(newdata)[1] != predNAME) stop("newdata should have name '", predNAME, "'!")
## get parameter coefficients
COEF <- coef(object)
## get variance-covariance matrix
VCOV <- vcov(object)
## augment variance-covariance matrix for 'mvrnorm'
## by adding a column/row for 'error in x'
NCOL <- ncol(VCOV)
ADD1 <- c(rep(0, NCOL))
ADD1 <- matrix(ADD1, ncol = 1)
colnames(ADD1) <- predNAME
VCOV <- cbind(VCOV, ADD1)
ADD2 <- c(rep(0, NCOL + 1))
ADD2 <- matrix(ADD2, nrow = 1)
rownames(ADD2) <- predNAME
VCOV <- rbind(VCOV, ADD2)
## iterate over all entries in 'newdata' as in usual 'predict.' functions
NR <- nrow(newdata)
respVEC <- numeric(NR)
seVEC <- numeric(NR)
varPLACE <- ncol(VCOV)
## define counter function
counter <- function(i) {
if (i%%10 == 0) { cat(i)
} else { cat(".") }
if (i%%50 == 0) { cat("\n") }
flush.console()
}
## create output matrix (df)
outMAT <- NULL
for (i in 1:NR) {
#counter(i)		# show a counter for lengthy fits; commented out to reduce noise here...
## get predictor values and optional errors
predVAL <- newdata[i, 1]
if (ncol(newdata) == 2) predERROR <- newdata[i, 2] else predERROR <- 0
names(predVAL) <- predNAME
names(predERROR) <- predNAME
## create mean vector for 'mvrnorm'
MU <- c(COEF, predVAL)
## create variance-covariance matrix for 'mvrnorm'
## by putting error^2 in lower-right position of VCOV
newVCOV <- VCOV
newVCOV[varPLACE, varPLACE] <- predERROR^2
## create MC simulation matrix
simMAT <- mvrnorm(n = nsim, mu = MU, Sigma = newVCOV, empirical = TRUE)
## evaluate expression on rows of simMAT
EVAL <- try(eval(EXPR, envir = as.data.frame(simMAT)), silent = TRUE)
if (inherits(EVAL, "try-error")) stop("There was an error evaluating the simulations!")
## collect statistics
PRED <- data.frame(predVAL)
colnames(PRED) <- predNAME
FITTED <- predict(object, newdata = data.frame(PRED))
MEAN.sim <- mean(EVAL, na.rm = TRUE)
SD.sim <- sd(EVAL, na.rm = TRUE)
MEDIAN.sim <- median(EVAL, na.rm = TRUE)
MAD.sim <- mad(EVAL, na.rm = TRUE)
QUANT <- quantile(EVAL, c((1 - level)/2, level + (1 - level)/2))
RES <- c(FITTED, MEAN.sim, SD.sim, MEDIAN.sim, MAD.sim, QUANT[1], QUANT[2])
outMAT <- rbind(outMAT, RES)
}
colnames(outMAT) <- c("fit", "mean", "sd", "median", "mad", names(QUANT[1]), names(QUANT[2]))
rownames(outMAT) <- NULL
#cat("\n")	# commented out along with the call to counter() above
return(outMAT)
}
## 3rd. perform analysis ##
w <- iMK(x, y, 0, 1)
## DGRP alpha removing 5 and 10%
##Remove % DGRP
### MUST OPTIMIZE! ###
DGRP <- function(x, y) {
out <- NULL
##### Not defined####
#names(x) <- c("daf","pN","pS")
mi <- as.numeric(y$m0f)
m0 <- as.numeric(y$m4f)
di <- as.numeric(y$D0f)
d0 <- as.numeric(y$D4f)
ns <- c(0.05, 0.1)
for (n in ns) {
x1 <- x[x$daf < n, ] #below DAF
x2 <- x[x$daf > n, ] #over DAF
#create table with raw values and < and > remove% values
t <- rbind(cbind(sum(x$pS),d0),cbind(sum(x$pN),di))
tab1 <- rbind(cbind(sum(x1$pS),sum(x2$pS)),cbind(sum(x1$pN),(sum(x2$pN))))
t <- cbind(t,tab1); t <- as.data.frame(t)
P0 <- t[1,1]; Pi <- t[2,1]
D0 <- t[1,2]; Di <- t[2,2]
P0b <- t[1,3]; Pib <- t[2,3]
P0o <- t[1,4]; Pio <- t[2,4]
fneutralb <- P0b / P0
Pineutralb <- Pi * fneutralb
Pi_wd <- Pib - Pineutralb
Pineutral <- round(Pineutralb + Pio)
if(Pineutral == "NaN") {Pineutral <- 0}
alpha <- 1 - ((Pineutral/P0) * (D0/Di))
m <- matrix(c(P0,Pineutral,D0,Di), ncol=2)
m1 <- fisher.test(m); m1 <- m1$p.value
g1 <- cbind(n,alpha,m1)
names(g1) <- c("cutoff","alpha","pval")
out <- rbind(out,g1)
names(out) <- c("cutoff","alpha","pval")
}
out <- as.data.frame(out)
names(out) <- c("cutoff","alpha","pval")
return(out)
}
## 3rd. perform analysis ##
w <- iMK(x, y, 0, 1)
w
## 3rd. perform analysis ##
w <- iMK(x, y, 0, 1)
w #check out results
## 2nd. read data ##
#setwd("...")
x <- read.table("RAL_Chr2L.txt", header=T) #polymorphism file (DAF)
## 3rd. perform analysis ##
w <- iMK(x, y, 0, 1)
## 2nd. read data ##
#setwd("...")
x <- read.table("RAL_Chr2L.txt", header=T) #polymorphism file (DAF)
y <- read.table("RAL_Chr2L_div.txt", header=T) #divergence and m file
## 3rd. perform analysis ##
w <- iMK(x, y, 0, 1)
## 2nd. read data ##
#setwd("...")
x <- read.table("RAL_Chr2L.txt", header=T) #polymorphism file (DAF)
y <- read.table("RAL_Chr2L_div.txt", header=T) #divergence and m file
## 3rd. perform analysis ##
w <- iMK(x, y, 0, 1)
w #check out results
## 2nd. read data ##
#setwd("...")
x <- read.table("RAL_Chr2L.txt", header=T) #polymorphism file (DAF)
y <- read.table("RAL_Chr2L_div.txt", header=T) #divergence and m file
## 3rd. perform analysis ##
w <- iMK(x, y, 0, 1)
w #check out results
## 2nd. read data ##
#setwd("...")
x <- read.table("RAL_Chr2L.txt", header=T) #polymorphism file (DAF)
y <- read.table("RAL_Chr2L_div.txt", header=T) #divergence and m file
## 3rd. perform analysis ##
w <- iMK(x, y, 0, 1)
function(x, y, xlow, xhigh){
data_is_good <- FALSE
######### Detecting if the colnames are the correct ones ############
if (!("daf" %in% colnames(x) & "pS" %in% colnames(x) & "pN" %in% colnames(x)))
stop("required header doesn't have the correct names: daf, pN, pS")
#error handling: check data formatting
if (NCOL(x) != 3)
stop("argument x does not contain exactly three tab-separated columns")
if (NROW(x) <= 0)
stop("argument x contains no data rows")
if (NCOL(y) != 6)
stop("argument y does not contain exactly six tab-separated columns")
if (NROW(y) <= 0)
stop("argument y contains no data rows")
##assign proper names to the columns of x and y. MUST CHECK THAT!
####Not defined######
#names(x) <- c("daf", "pN", "pS")
#names(y) <- c("Chr",  "Pop",	"m0f",	"D0f",	"m4f",	"D4f")
#error handling: input colnames
#for arg x
x.cols <- names(x)
suppressWarnings(#the goal is to generate NAs here, so we dont need no warnings
if (!is.na(as.numeric(x.cols[1])) ||
!is.na(as.numeric(x.cols[2])) ||
!is.na(as.numeric(x.cols[3])))
stop("argument x has a numeric column name;
probably the required header row is missing"))
#for arg y
y.cols <- names(y)
suppressWarnings(
if (!is.na(as.numeric(y.cols[1])) ||
!is.na(as.numeric(y.cols[2])) ||
!is.na(as.numeric(y.cols[3])) ||
!is.na(as.numeric(y.cols[4])) ||
!is.na(as.numeric(y.cols[5])) ||
!is.na(as.numeric(y.cols[6])))
stop("argument y has a numeric column name;
probably the required header row is missing")
)
##parse the data from argument x
####### dependent on the column name
f <- x$daf #derived alelle frequencies
p <- x$pN #non-synonymous polymorphism
p0 <- x$pS #synonymous polymorphism
#error handling: check if variables are good
if (any(is.na(f)))
stop("f contains NA values (not allowed)")
if (any(is.na(p)))
stop("p contains NA values (not allowed)")
if (any(is.na(p0)))
stop("p0 contains NA values (not allowed)")
if (is.null(f))
stop("f malformed (must be numeric)")
if (is.null(p))
stop("p malformed (must be numeric)")
if (is.null(p0))
stop("p0 malformed (must be numeric)")
#error handling: check if variables are numeric
if (!is.numeric(f))
stop("f is not numeric")
if (!is.numeric(p))
stop("p is not numeric")
if (!is.numeric(p0))
stop("p0 is not numeric")
#error handling: check if variables are not out of bounds
if (any(f < 0.0) || any(f > 1.0))
stop("f contains values out of the required range [0,1]")
if (all(f == 0))
stop("f contains all values == 0 (not allowed)")
if (any(p < 0))   # note that zero is allowed, although not recommended
stop("p contains values < 0 (not allowed)")
if (all(p == 0))    # not all can be zero, however
stop("p contains all values == 0 (not allowed)")
if (any(p0 <= 0))
stop("p0 contains values <= 0 (not allowed)")
if (all(p0 == 0))
stop("p0 contains all values == 0 (not allowed)")
#error handling: check if argument x has enough data points
if (NROW(x) < 3)
stop("argument x: at least three data rows are required to constrain the fit")
##parse the data from argument y and force it to be numeric...
m <- as.numeric(y$m0f) #number of non-synonymous sites
m0 <- as.numeric(y$m4f) ##number of synonymous sites
d <- as.numeric(y$D0f) #non-synonymous divergence
d0 <- as.numeric(y$D4f) #synonymous divergence
#error handling: check if variables are good
if (is.na(m) || is.null(m))
stop("malformed m (must be numeric)")
if (is.na(m0) || is.null(m0))
stop("malformed m0 (must be numeric)")
if (is.na(d0) || is.null(d0))
stop("malformed d0 (must be numeric)")
if (is.na(d) || is.null(d))
stop("malformed d (must be numeric)")
if (is.na(xlow) || is.null(xlow))
stop("malformed xlow (must be numeric)")
if (is.na(xhigh) || is.null(xhigh))
stop("malformed xhigh (must be numeric)")
# Checks if number of sites (m, m0) is not higher than divergenge (d, d0), the sum of the polimorphisms (p|p0) or the divergenge + the sum of the polimorphsms
if (d>m || sum(p)>m || sum(p)+d>m)
stop("m must be higher than p, d and p+d")
if (d0>m0 || sum(p0)>m0 || sum(p)+d0>m0)
stop("m0 must be higher than p0, d0 and p0+d0")
#error handling: check if variables are numeric
#it makes no sence as we forced them to be numeric... should check that!
if (!is.numeric(m))
stop("m is not numeric")
if (!is.numeric(m0))
stop("m0 is not numeric")
if (!is.numeric(d))
stop("d is not numeric")
if (!is.numeric(d0))
stop("d0 is not numeric")
#error handling: check if variables are not out of bounds
if (m <= 0)
stop("m must be greater than zero")
if (m0 <= 0)
stop("m0 must be greater than zero")
if (d0 <= 0)
stop("d0 must be greater than zero")
if (d <= 0)
stop("d must be greater than zero")
#error handling: check if cutoff values not null
if (is.na(xlow) || is.null(xlow))
stop("malformed xlow (must be numeric)")
if (is.na(xhigh) || is.null(xhigh))
stop("malformed xhigh (must be numeric)")
#error handling: check if cutoff values are numeric
if (!is.numeric(xlow))
stop("xlow is not numeric")
if (!is.numeric(xhigh))
stop("xhigh is not numeric")
#error handling: check if cutoff values are not out of bounds
if ((xlow < 0.0) || (xlow > 1.0))
stop("xlow must be in the interval [0,1]")
if ((xhigh < 0.0) || (xhigh > 1.0))
stop("xhigh must be in the interval [0,1]")
if (xhigh <= xlow)
stop("xhigh must be greater than xlow")
cutoff_f1 <- xlow
cutoff_f2 <- xhigh
trim <- ((f >= cutoff_f1) & (f <= cutoff_f2))
#error handling: check if trimmed f has enough data points
if (sum(trim) < 3)
stop("Argument x: at least 3 data rows are required to constrain the fit;
after trimming the frequency range there are less than 3.
Consider changing cutoff values or not trimming your data.")
data_is_good <- TRUE
#writeLines("data is good: TRUE\n")
return(data_is_good)
}
## 2nd. read data ##
#setwd("...")
x <- read.table("RAL_Chr2L.txt", header=T) #polymorphism file (DAF)
y <- read.table("RAL_Chr2L_div.txt", header=T) #divergence and m file
## 3rd. perform analysis ##
w <- iMK(x, y, 0, 1)
